# -*- coding: utf-8 -*-
"""
MedInfo-Check AI â€“ Streamlit + OpenAI Assistants v2
(Custom Composer + OCR + Assistant-driven Compliance Analysis)
================================================================================
2025-07-17
"""

###############################################################################
# Imports & ê¸°ë³¸ ì„¤ì •
###############################################################################
import os, time, tempfile, re, inspect, io, json, textwrap
from importlib.metadata import version as _pkg_version
from typing import List, Dict, Tuple, Any

import streamlit as st
import openai

import fitz, pdfplumber, docx2txt
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# OCR
try:
    from PIL import Image
except ImportError:
    Image = None
try:
    import pytesseract
except ImportError:
    pytesseract = None

###############################################################################
# Page config
###############################################################################
st.set_page_config(page_title="MedInfo-Check AI", page_icon="ğŸ’Š", layout="wide")

###############################################################################
# Inject CSS (ChatGPT-like í•˜ë‹¨ ê³ ì • ì…ë ¥ì°½ ìŠ¤íƒ€ì¼)
###############################################################################
CUSTOM_CSS = """
<style>
.block-container { padding-bottom: 8rem !important; } /* í•˜ë‹¨ ì»´í¬ì € ê³µê°„ í™•ë³´ */
#chat-composer-container {
    position: fixed; left: 0; right: 0; bottom: 0; z-index: 999;
    padding: 0.75rem 1.25rem;
    background: var(--background-color, #0e1117);
    box-shadow: 0 -2px 16px rgb(0 0 0 / 40%);
}
.chat-composer-box {
    width: 100%; max-width: 900px; margin: 0 auto;
    background: rgba(250,250,250,0.05);
    border: 1px solid rgba(250,250,250,0.15);
    border-radius: 12px;
    padding: 0.75rem 1rem;
}
.chat-composer-box .stFileUploader label { display: none !important; }
.chat-composer-box .stButton>button { width: 100%; border-radius: 8px; }
.chat-composer-box textarea { min-height: 80px !important; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

###############################################################################
# OpenAI ì„¤ì • (ì„¹ì…˜ ìš°ì„ , ë£¨íŠ¸ í‚¤ fallback)
###############################################################################
SEC = st.secrets.get("openai", {})
ROOT = st.secrets

OPENAI_API_KEY = SEC.get("api_key") or ROOT.get("OPENAI_API_KEY", "") or ROOT.get("api_key", "")
ASSISTANT_ID   = SEC.get("assistant_id") or ROOT.get("ASSISTANT_ID", "")
MODEL_NAME     = SEC.get("model") or ROOT.get("MODEL_NAME", "gpt-4o-mini")
OPENAI_ORG     = SEC.get("org") or ROOT.get("OPENAI_ORG", "")

if not OPENAI_API_KEY:
    st.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤ â€“ .streamlit/secrets.toml í™•ì¸!")
    st.stop()

openai.api_key = OPENAI_API_KEY
if OPENAI_ORG:
    openai.organization = OPENAI_ORG

# openai íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸
try:
    major, minor = map(int, _pkg_version("openai").split(".")[:2])
    assert (major, minor) >= (1, 14)
except Exception:
    st.error("openai 1.14.0 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤  â†’  pip install -U 'openai>=1.14.0'")
    st.stop()

###############################################################################
# Assistant ID ì¡°íšŒ (ìƒì„± ì—†ìŒ)
###############################################################################
def get_assistant_id() -> str:
    """secrets ì— ì§€ì •ëœ ê¸°ì¡´ Assistant ID ë°˜í™˜."""
    if not ASSISTANT_ID or not ASSISTANT_ID.strip():
        st.error("ê¸°ì¡´ Assistant ID(assistant_id)ê°€ secrets.toml ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    return ASSISTANT_ID.strip()

###############################################################################
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
###############################################################################
def ensure_chat_state():
    if "chat_thread" not in st.session_state:
        th = openai.beta.threads.create()
        st.session_state.chat_thread = th.id
    if "chats" not in st.session_state:
        st.session_state.chats = []   # [(role, md_text)]
    if "active_run_id" not in st.session_state:
        st.session_state.active_run_id = None

###############################################################################
# Run ìƒíƒœ í´ë§
###############################################################################
def _wait_for_run_completion(thread_id: str, run_id: str, poll: float = 0.3, timeout: float = 300.0):
    """ì£¼ê¸°ì ìœ¼ë¡œ Run ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì™„ë£Œë˜ë©´ Run ê°ì²´ ë°˜í™˜."""
    start = time.time()
    while True:
        run = openai.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)
        if run.status in {"completed", "failed", "cancelled", "expired"}:
            return run
        # file_search ë“± ìë™ íˆ´ ì‚¬ìš© ì¤‘: in_progress, queued ë“± ê³„ì† ëŒ€ê¸°
        if time.time() - start > timeout:
            raise TimeoutError("Run ì²˜ë¦¬ ì‹œê°„ì´ ì‹œê°„ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
        time.sleep(poll)

###############################################################################
# í…ìŠ¤íŠ¸ ì •ë¦¬ & Bullet Split
###############################################################################
def clean_text(txt: str) -> str:
    repl = {
        "\u2011": "-",
        "\u2013": "-",
        "\u2014": "-",
        "\u2018": "'",
        "\u2019": "'",
        "\u201C": '"',
        "\u201D": '"',
        "\u2022": "*",
    }
    for bad, good in repl.items():
        txt = txt.replace(bad, good)
    return " ".join(txt.split())

def split_bullets(s: str) -> List[str]:
    return [ln.lstrip("*-â€¢ ").strip() for ln in s.splitlines() if ln.strip()]

###############################################################################
# File â†’ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¡œì»¬ ìš”ì•½/ìœ„í—˜ íƒì§€ìš©)
###############################################################################
def extract_text(file) -> str:
    """UploadedFile ì„ ë°›ì•„ í…ìŠ¤íŠ¸ ì¶”ì¶œ."""
    ext = os.path.splitext(file.name)[1].lower()
    file.seek(0)
    try:
        if ext == ".pdf":
            with fitz.open(stream=file.read(), filetype="pdf") as doc:
                return clean_text("\n".join(p.get_text() for p in doc))
        if ext in {".doc", ".docx"}:
            data = file.read()
            tmp = tempfile.mktemp(suffix=ext)
            with open(tmp, "wb") as f:
                f.write(data)
            txt = docx2txt.process(tmp)
            os.remove(tmp)
            return clean_text(txt)
        if ext in {".ppt", ".pptx"}:
            data = file.read()
            tmp = tempfile.mktemp(suffix=ext)
            with open(tmp, "wb") as f:
                f.write(data)
            prs = Presentation(tmp)
            txts = []
            for slide in prs.slides:
                for shp in slide.shapes:
                    if shp.shape_type == MSO_SHAPE_TYPE.TEXT_BOX or getattr(shp, "text", None):
                        txts.append(shp.text)
            os.remove(tmp)
            return clean_text("\n".join(txts))
    except Exception:
        pass
    # fallback
    if ext == ".pdf":
        file.seek(0)
        with pdfplumber.open(file) as pdf:
            return clean_text("\n".join(p.extract_text() or "" for p in pdf.pages))
    return ""

###############################################################################
# ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜ ìœ„í—˜ íƒì§€ (ì¦‰ì‹œ ê²½ê³ ìš©)
###############################################################################
DEFAULT_RULES = {
    "banned_keywords": ["100% ì¹˜ë£Œ", "ì™„ì¹˜", "ë¶€ì‘ìš© ì—†ìŒ"],
    "off_label_patterns": [r"ì•”\s*ì¹˜ë£Œ", r"ì²´ì¤‘\s*ê°ì†Œ"],
}
def detect_risk(text: str) -> List[Tuple[str, str]]:
    result = [(kw, "banned_keyword") for kw in DEFAULT_RULES["banned_keywords"] if kw in text]
    for pat in DEFAULT_RULES["off_label_patterns"]:
        result += [(m.group(0), "off_label") for m in re.finditer(pat, text, flags=re.I)]
    return result

###############################################################################
# ë‚´ì¥ ê·œì • ìš”ì•½ (ê·œì • ë¬¸ì„œ ì—†ì„ ë•Œ ì‚¬ìš©)
###############################################################################
BUILTIN_REG_SUMMARY = textwrap.dedent("""
ì£¼ìš” í•œêµ­ ì˜ì•½í’ˆê´‘ê³  ì‹¬ì˜ ì²´í¬í¬ì¸íŠ¸ (ìš”ì•½):
- í—ˆê°€/ì‹ ê³ ì‚¬í•­ ì™¸ íš¨ëŠ¥Â·íš¨ê³¼, ìš©ë²•Â·ìš©ëŸ‰ ê´‘ê³  ê¸ˆì§€.
- ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ê±°ë‚˜ ì†Œë¹„ìë¥¼ ì˜¤ì¸í•˜ê²Œ í•˜ëŠ” í‘œí˜„ ê¸ˆì§€.
- 'ìµœê³ ', 'ìµœìƒ', '100%', 'ì™„ì¹˜', 'ë¶€ì‘ìš© ì—†ìŒ' ë“± ì ˆëŒ€ì /ê³¼ì¥ í‘œí˜„ ê¸ˆì§€.
- ë¶€ì‘ìš©ì„ ì€íí•˜ê±°ë‚˜ ì•ˆì „ì„±ì„ ê³¼ì¥í•˜ëŠ” í‘œí˜„ ê¸ˆì§€.
- íŠ¹ì • ì „ë¬¸ê°€(ì˜ì‚¬/ì•½ì‚¬ ë“±) ëª…ì˜ ì¶”ì²œ ê´‘ê³  ê¸ˆì§€(ë²•ë ¹ í—ˆìš© ì˜ˆì™¸ ì œì™¸).
- ì‚¬ìš© ì „í›„ ë¹„êµ, ì²´í—˜ë‹´/ê°ì‚¬ì¥/ì£¼ë¬¸ ì‡„ë„ ë“± ì¦ì–¸ì„± ê´‘ê³  ì£¼ì˜.
""").strip()

###############################################################################
# OCR ìœ í‹¸
###############################################################################
def ocr_image_from_bytes(data: bytes, lang: str = "eng+kor") -> str:
    if Image is None or pytesseract is None:
        return ""
    try:
        img = Image.open(io.BytesIO(data)).convert("RGB")
        return pytesseract.image_to_string(img, lang=lang)
    except Exception:
        return ""

###############################################################################
# íŒŒì¼ ì—…ë¡œë“œ â†’ OpenAI Files (ê³µí†µ)
###############################################################################
IMAGE_EXTS = {".png", ".jpg", ".jpeg", ".gif", ".webp"}
DOC_EXTS   = {".pdf", ".doc", ".docx", ".ppt", ".pptx", ".txt", ".md", ".html", ".htm"}

# OpenAI File Search ì§€ì› í™•ì¥ì(ì•ˆì „ ì„œë¸Œì…‹)
SUPPORTED_FILE_SEARCH_EXTS = {
    ".c",".cs",".cpp",".doc",".docx",".html",".htm",".java",".json",".md",".pdf",
    ".php",".pptx",".py",".rb",".tex",".txt",".css",".js",".sh",".ts",
}

def _upload_single_file_bytes(data: bytes, original_name: str, purpose: str):
    ext = os.path.splitext(original_name)[1] or ".bin"
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=ext)
    try:
        tmp.write(data)
        tmp.flush(); tmp.close()
        with open(tmp.name, "rb") as fh:
            resp = openai.files.create(file=fh, purpose=purpose)
    finally:
        try: os.remove(tmp.name)
        except Exception: pass
    return resp

def upload_files_generic(files, purpose_map=None, force_purpose=None, ocr=False):
    """ê³µí†µ ì—…ë¡œë“œ: Streamlit UploadedFile ë¦¬ìŠ¤íŠ¸ â†’ OpenAI Files + ë©”íƒ€."""
    results=[]
    for uf in files:
        uf.seek(0); data = uf.read()
        ext = os.path.splitext(uf.name)[1].lower()
        if force_purpose:
            purpose = force_purpose
        else:
            if purpose_map is not None:
                purpose = purpose_map(ext)
            else:
                purpose = "vision" if ext in IMAGE_EXTS else "assistants"
        resp = _upload_single_file_bytes(data, uf.name, purpose)
        item = {
            "file_id": resp.id,
            "name": uf.name,
            "ext": ext,
            "is_image": ext in IMAGE_EXTS,
            "retrieval_ok": (ext in SUPPORTED_FILE_SEARCH_EXTS),
        }
        if ocr and item["is_image"]:
            item["ocr_text"] = ocr_image_from_bytes(data)
        results.append(item)
    return results

###############################################################################
# Assistant ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
###############################################################################
def build_compliance_prompt(filenames_review: List[str],
                            filenames_refs: List[str],
                            filenames_regs: List[str],
                            reg_summary: str) -> str:
    return f"""
ë‹¹ì‹ ì€ í•œêµ­ì œì•½ë°”ì´ì˜¤í˜‘íšŒ ì˜ì•½í’ˆê´‘ê³ ì‹¬ì˜ìœ„ì›íšŒ ì‹¬ì˜ê´€ì…ë‹ˆë‹¤.

ì•„ë˜ ì²¨ë¶€ëœ **ê²€í†  ìë£Œ(Review Materials)** ì— í¬í•¨ëœ ëª¨ë“  ê´‘ê³ /í”„ë¡œëª¨ì…˜ì„± ì£¼ì¥(Key Messages)ì„ ì¶”ì¶œí•˜ê³ ,
ì²¨ë¶€ëœ **ê·œì • ë¬¸ì„œ(Regulations)** ë° **ì°¸ê³  ë¬¸í—Œ(References)** ì„ ê·¼ê±°ë¡œ
í•œêµ­ ì˜ì•½í’ˆê´‘ê³  ê´€ë ¨ ë²•ë ¹ ë° ì‹¬ì˜ê¸°ì¤€ ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ì„¸ìš”.

### íŒŒì¼ ë¶„ë¥˜
- Review: {', '.join(filenames_review) or '(ì—†ìŒ)'}
- References: {', '.join(filenames_refs) or '(ì—†ìŒ)'}
- Regulations: {', '.join(filenames_regs) or '(ì—†ìŒ)'}

### ê·œì • ìš”ì•½
{reg_summary}

### í‰ê°€ ê¸°ì¤€ íƒœê·¸
í—ˆê°€ì™¸íš¨ëŠ¥, ê³¼ì¥, ì ˆëŒ€í‘œí˜„, ì•ˆì „ì„±ê³¼ì¥, ì „ë¬¸ê°€ì¶”ì²œ, ë¹„êµí‘œì‹œ, ì†Œë¹„ìì˜¤ì¸, ê¸°íƒ€

### ì¶œë ¥ í˜•ì‹(JSONë§Œ):
[
 {{"claim":"...", "status":"COMPLIANT|MINOR_FIX|POTENTIAL_VIOLATION|VIOLATION|NEEDS_EVIDENCE",
   "issue_tags":["í—ˆê°€ì™¸íš¨ëŠ¥",...],
   "law_refs":["ì•½ì‚¬ë²• ì œ68ì¡°","ê·œì¹™ ë³„í‘œ7 2.ê°€"],
   "rationale_kor":"ì™œ í•´ë‹¹ ë“±ê¸‰ì¸ì§€ ê°„ëµ ì„¤ëª…",
   "suggestion_kor":"ê·œì • ë¶€í•©í•˜ë„ë¡ ìˆ˜ì •ì•ˆ"
 }},
 ...
]

JSON ì´ì™¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
""".strip()

###############################################################################
# Assistant ë¶„ì„ ì‹¤í–‰
###############################################################################
def run_assistant_compliance_analysis(rv_meta: List[Dict],
                                      ref_meta: List[Dict],
                                      reg_meta: List[Dict],
                                      img_meta: List[Dict],
                                      reg_text_fallback: str) -> Dict:
    """
    ì²¨ë¶€ ë©”íƒ€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Assistantì—ê²Œ ê·œì • ì¤€ìˆ˜ ë¶„ì„ì„ ìš”ì²­í•˜ê³  ê²°ê³¼(JSON)ë¥¼ ë°˜í™˜.
    rv_meta/ref_meta/reg_meta/img_meta: upload_files_generic() ê²°ê³¼ ë¦¬ìŠ¤íŠ¸.
    """
    # ìƒˆ Thread (ë¶„ì„ ì „ìš©)
    thread = openai.beta.threads.create()
    thread_id = thread.id

    # íŒŒì¼ ê²€ìƒ‰ ì²¨ë¶€: ì§€ì› í™•ì¥ìë§Œ
    all_docs = rv_meta + ref_meta + reg_meta
    attachments = [
        {"file_id": m["file_id"], "tools": [{"type": "file_search"}]}
        for m in all_docs if m.get("retrieval_ok")
    ]

    # ê·œì • ìš”ì•½ í…ìŠ¤íŠ¸
    filenames_review = [m["name"] for m in rv_meta]
    filenames_refs   = [m["name"] for m in ref_meta]
    filenames_regs   = [m["name"] for m in reg_meta]

    reg_summary = reg_text_fallback or BUILTIN_REG_SUMMARY

    prompt_text = build_compliance_prompt(filenames_review, filenames_refs, filenames_regs, reg_summary)

    # ë©”ì‹œì§€ content: ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ + ì—…ë¡œë“œ ì´ë¯¸ì§€(ê²€í†  ì´ë¯¸ì§€)
    content = [{"type": "text", "text": prompt_text}]
    for m in img_meta:
        content.append({"type": "image_file", "image_file": {"file_id": m["file_id"]}})
        if m.get("ocr_text"):
            content.append({"type": "text", "text": f"[OCR {m['name']}]\n{m['ocr_text'][:2000]}"} )

    # ë©”ì‹œì§€ ìƒì„±
    openai.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=content,
        attachments=attachments if attachments else None,
    )

    # Run ìƒì„± (ì¶”ê°€ instructions ì—†ì´; Assistant ê¸°ë³¸ + ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜)
    run = openai.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=get_assistant_id(),
    )

    # ëŒ€ê¸°
    with st.spinner("ê·œì • ì¤€ìˆ˜ ë¶„ì„ ì¤‘â€¦(Assistant)"):
        run = _wait_for_run_completion(thread_id, run.id)

    if run.status != "completed":
        return {"error": f"run status={run.status}"}

    # ë©”ì‹œì§€ ìˆ˜ì§‘
    msgs = openai.beta.threads.messages.list(thread_id=thread_id, order="desc")

    raw = None
    for m in msgs.data:
        if m.role == "assistant":
            parts = []
            for part in getattr(m, "content", []):
                t = getattr(part, "type", None)
                if t == "text" and hasattr(part, "text"):
                    parts.append(part.text.value)
                elif isinstance(part, dict) and part.get("type") == "text":
                    parts.append(part.get("text", ""))
            raw = "\n".join(parts).strip()
            break

    if raw is None:
        return {"error": "no assistant response"}

    # JSON íŒŒì‹± ì‹œë„
    parsed = None
    try:
        parsed = json.loads(raw)
    except Exception:
        # JSON ì¶”ì¶œ (ì²« [ ... ] ë²”ìœ„)
        m = re.search(r'(\[.*\])', raw, flags=re.S)
        if m:
            try:
                parsed = json.loads(m.group(1))
            except Exception:
                pass
    if not isinstance(parsed, list):
        parsed = []

    return {
        "assistant_raw": raw,
        "parsed": parsed,
    }

###############################################################################
# Chat ì œì¶œ ì²˜ë¦¬ (ì „ì—­ ì»¤ìŠ¤í…€ ì…ë ¥ì°½ â†’ Chat Thread)
###############################################################################
def _send_user_message_and_run(text: str, uploaded: List[Dict]):
    """ì‹¤ì œ API í˜¸ì¶œ & ì‘ë‹µ ì²˜ë¦¬ (Chat Thread)."""
    ensure_chat_state()

    # ë©”ì‹œì§€ ì½˜í…ì¸  ì¤€ë¹„
    content = []
    if text:
        content.append({"type": "text", "text": text})
    for item in uploaded:
        if item["is_image"]:
            content.append({"type": "image_file", "image_file": {"file_id": item["file_id"]}})
            if item.get("ocr_text"):
                content.append({"type": "text", "text": f"[OCR {item['name']}]\n{item['ocr_text'][:2000]}"} )

    # ë¬¸ì„œ ì²¨ë¶€ (ê²€ìƒ‰/ì°¸ì¡°ìš©) â€” ì§€ì› í™•ì¥ìë§Œ
    doc_attachments = [
        {"file_id": item["file_id"], "tools": [{"type": "file_search"}]}
        for item in uploaded if (not item["is_image"]) and item.get("retrieval_ok")
    ]
    skipped_docs = [item["name"] for item in uploaded if (not item["is_image"]) and not item.get("retrieval_ok")]

    if skipped_docs:
        content.append({
            "type": "text",
            "text": f"(file_search ë¯¸ì§€ì› í™•ì¥ì: {', '.join(skipped_docs)})"
        })

    if not content:
        content.append({"type": "text", "text": "(íŒŒì¼ ì²¨ë¶€)"})

    # ë©”ì‹œì§€ ìƒì„±
    try:
        openai.beta.threads.messages.create(
            thread_id=st.session_state.chat_thread,
            role="user",
            content=content,
            attachments=doc_attachments if doc_attachments else None,
        )
    except Exception as e:
        st.error(f"ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # ë¡œì»¬ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    attach_names = ", ".join(it["name"] for it in uploaded) if uploaded else ""
    display_md = text or ""
    if attach_names:
        display_md += f"\n\nğŸ“ ì²¨ë¶€: {attach_names}"
        if skipped_docs:
            display_md += f"\nâš ï¸ ê²€ìƒ‰ ë¯¸ì§€ì› í™•ì¥ì: {', '.join(skipped_docs)}"
    st.session_state.chats.append(("user", display_md))
    st.chat_message("user").markdown(display_md)

    # Run ìƒì„±
    try:
        run = openai.beta.threads.runs.create(
            thread_id=st.session_state.chat_thread,
            assistant_id=get_assistant_id(),
        )
    except Exception as e:
        st.error(f"Run ìƒì„± ì‹¤íŒ¨: {e}")
        return
    st.session_state.active_run_id = run.id

    # ëŒ€ê¸°
    with st.spinner("Assistant typingâ€¦"):
        try:
            run = _wait_for_run_completion(st.session_state.chat_thread, run.id)
        except TimeoutError as e:
            st.error(str(e)); return
    st.session_state.active_run_id = None

    if run.status != "completed":
        st.error(f"Assistant run failed: {run.status}")
        return

    # ì‘ë‹µ
    msgs = openai.beta.threads.messages.list(thread_id=st.session_state.chat_thread, order="desc")
    ans = "(no response)"
    for m in msgs.data:
        if m.role == "assistant":
            parts=[]
            for part in getattr(m,"content",[]):
                if getattr(part,"type",None)=="text" and hasattr(part,"text"):
                    parts.append(part.text.value)
                elif isinstance(part,dict) and part.get("type")=="text":
                    parts.append(part.get("text",""))
            if parts: ans="\n".join(parts)
            break

    st.session_state.chats.append(("assistant", ans))
    st.chat_message("assistant").markdown(ans)

def process_chat_submission_from_form(text: str, files: List[Any]):
    """ì»¤ìŠ¤í…€ í¼ ì œì¶œê°’(text, files)ì„ Assistants Thread ë¡œ ì „ì†¡."""
    if not text and not files:
        return
    active_id = st.session_state.get("active_run_id")
    if active_id:
        _wait_for_run_completion(st.session_state.chat_thread, active_id)
        st.session_state.active_run_id = None
    uploaded = upload_files_generic(files, ocr=True)
    _send_user_message_and_run(text, uploaded)

###############################################################################
# Chat ì„¹ì…˜ (íˆìŠ¤í† ë¦¬ í‘œì‹œë§Œ)
###############################################################################
def chat_ui():
    """Chat ì„¹ì…˜ì— ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ (ì…ë ¥ì°½ì€ í•˜ë‹¨ ì»¤ìŠ¤í…€)."""
    ensure_chat_state()
    st.subheader("ğŸ’¬ Chat with AI")
    for role, msg in st.session_state.chats:
        st.chat_message(role).markdown(msg)
    st.caption("ì•„ë˜ ì…ë ¥ì°½ì—ì„œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì„¸ìš”. ë¬¸ì„œ/ì´ë¯¸ì§€ ì²¨ë¶€ ì§€ì›.")

###############################################################################
# Document Analysis ì„¹ì…˜ (Assistant í˜¸ì¶œ)
###############################################################################
def analysis_ui():
    st.subheader("ğŸ“‘ Document Analysis")

    rv_files  = st.file_uploader("ê²€í†  ìë£Œ", ["pdf", "doc", "docx", "ppt", "pptx"], accept_multiple_files=True)
    ref_files = st.file_uploader("ì°¸ê³  ë…¼ë¬¸", ["pdf", "doc", "docx", "ppt", "pptx"], accept_multiple_files=True)
    reg_files = st.file_uploader("ê·œì • ë¬¸ì„œ (ì„ íƒ)", ["pdf", "doc", "docx", "ppt", "pptx"], accept_multiple_files=True)
    img_files = st.file_uploader("ê´‘ê³  ì´ë¯¸ì§€ (ì„ íƒ)", ["png", "jpg", "jpeg", "gif", "webp"], accept_multiple_files=True)

    if rv_files and st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
        # ë¡œì»¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ìœ„í—˜ íŒ¨í„´
        with st.spinner("ë¡œì»¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘â€¦"):
            tgt_text  = "\n\n".join(extract_text(f) for f in rv_files)
            ref_texts = [extract_text(f) for f in (ref_files or [])]
            reg_texts = [extract_text(f) for f in (reg_files or [])]
            reg_text  = "\n\n".join(rt for rt in reg_texts if rt.strip())

        risk = detect_risk(tgt_text)

        # íŒŒì¼ ì—…ë¡œë“œ(OpenAI) - ë¶„ì„ìš©
        with st.spinner("íŒŒì¼ ì—…ë¡œë“œ ì¤‘â€¦"):
            rv_meta  = upload_files_generic(rv_files, ocr=False)   # ë¬¸ì„œ
            ref_meta = upload_files_generic(ref_files or [], ocr=False)
            reg_meta = upload_files_generic(reg_files or [], ocr=False)
            img_meta = upload_files_generic(img_files or [], ocr=True)  # ì´ë¯¸ì§€+OCR

        # Assistant ë¶„ì„ ìš”ì²­
        res_assistant = run_assistant_compliance_analysis(
            rv_meta=rv_meta,
            ref_meta=ref_meta,
            reg_meta=reg_meta,
            img_meta=img_meta,
            reg_text_fallback=reg_text or BUILTIN_REG_SUMMARY,
        )

        st.success("ë¶„ì„ ì™„ë£Œ!")

        # --- ìœ„í—˜ í‘œí˜„ (ë¡œì»¬ ë£°) ------------------------------------------------
        with st.expander("âš ï¸ ìœ„í—˜ í‘œí˜„ (ê°„ì´ íƒì§€)"):
            if not risk:
                st.write("ìœ„í—˜ í‘œí˜„ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                for p, t in risk:
                    st.write(f"â€¢ {p} | {t}")

        # --- Assistant ê·œì • ì¤€ìˆ˜ ë¶„ì„ ------------------------------------------
        with st.expander("âœ… ê·œì • ì¤€ìˆ˜ (Assistant ë¶„ì„)"):
            if "error" in res_assistant:
                st.error(res_assistant["error"])
            else:
                parsed = res_assistant.get("parsed", [])
                if not parsed:
                    st.write("JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë¬¸:")
                    st.code(res_assistant.get("assistant_raw","(ì—†ìŒ)"), language="json")
                else:
                    for item in parsed:
                        icon = {
                            "COMPLIANT": "âœ…",
                            "MINOR_FIX": "ğŸŸ¡",
                            "POTENTIAL_VIOLATION": "âš ï¸",
                            "VIOLATION": "ğŸš«",
                            "NEEDS_EVIDENCE": "â“",
                        }.get(item.get("status",""), "â“")
                        st.markdown(f"**{icon} {item.get('claim','')}**")
                        if item.get("rationale_kor"): st.write(item["rationale_kor"])
                        if item.get("law_refs"):
                            st.caption("ê·¼ê±°: " + ", ".join(item["law_refs"]))
                        if item.get("suggestion_kor"):
                            st.info(item["suggestion_kor"])
                        st.markdown("---")

        # --- ì›ë¬¸ JSON ë³´ê¸° -----------------------------------------------------
        with st.expander("ğŸ§¾ Assistant Raw JSON ì‘ë‹µ"):
            st.code(res_assistant.get("assistant_raw",""), language="json")

###############################################################################
# í•˜ë‹¨ ChatGPT ìŠ¤íƒ€ì¼ ì»´í¬ì €
###############################################################################
def chat_composer(show: bool):
    """í•˜ë‹¨ ê³ ì • ì…ë ¥ì°½. show=True ì¸ ê²½ìš°ì—ë§Œ ë Œë”."""
    if not show:
        return

    disabled = st.session_state.get("active_run_id") is not None

    st.markdown('<div id="chat-composer-container">', unsafe_allow_html=True)
    with st.container():
        st.markdown('<div class="chat-composer-box">', unsafe_allow_html=True)

        # í¼ (ì—”í„° ëŒ€ì‹  ëª…ì‹œì  ì „ì†¡ ë²„íŠ¼; clear_on_submit=True)
        with st.form("chat_composer_form", clear_on_submit=True):
            files = st.file_uploader(
                "íŒŒì¼ ì²¨ë¶€",
                type=None,  # ëª¨ë“  í™•ì¥ì í—ˆìš©
                accept_multiple_files=True,
                disabled=disabled,
                label_visibility="collapsed",
                key="composer_files",
            )
            text = st.text_area(
                "ë©”ì‹œì§€",
                placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ ì˜ì—­ì— íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì„¸ìš”â€¦",
                disabled=disabled,
                label_visibility="collapsed",
                key="composer_text",
            )
            send_col1, send_col2, send_col3 = st.columns([6,1,1])
            with send_col2:
                submitted = st.form_submit_button("ë³´ë‚´ê¸°", disabled=disabled)
            with send_col3:
                st.form_submit_button("ì·¨ì†Œ", disabled=disabled)

        st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

    if 'submitted' in locals() and submitted and not disabled:
        process_chat_submission_from_form(text, files or [])

###############################################################################
# ë©”ì¸ ë ˆì´ì•„ì›ƒ
###############################################################################
def main():
    ensure_chat_state()

    st.title("MedInfo-Check AI")

    # ì„¹ì…˜ ì„ íƒ
    section = st.radio(
        " ",
        options=("ğŸ“‘ Document Analysis", "ğŸ’¬ Chat with AI"),
        index=0,
        horizontal=True,
        label_visibility="collapsed",
        key="main_section_selector",
    )

    if section.startswith("ğŸ“‘"):
        analysis_ui()
        show_chat_input = False
    else:
        chat_ui()
        show_chat_input = True

    # í•˜ë‹¨ ì»´í¬ì € (Chat ì„¹ì…˜ì—ì„œë§Œ)
    chat_composer(show_chat_input)

    st.caption("Â© 2025 MedInfo-Check AI")

if __name__ == "__main__":
    main()
